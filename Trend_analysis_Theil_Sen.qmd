---
author: BenS
date: "`r Sys.Date()`"
title: "Theil-Sen Trend Analysis Using Environment Cantebrury Data"
format:
  html:
    self-contained: true
    table-of-contents: true
    toc-location: left
execute:
  warning: false
  message: false
---

```{r}
#| label: setup

knitr::opts_chunk$set(echo = TRUE)
library(tidyverse, warn.conflicts = FALSE)
library(httr)
library(DBI)

```

## Introduction

This is an rmarkdown document showing how to calculate 10 year trends calculated using Environment Canterbury data. This is a working document and likely to update and change.

The steps shown are from getting data, cleaning the data (with some decisions on analysis) and finally running the trend calculation. The trends are calculated using the `TheilSen` function from the `openair` package.

::: callout-note

There are some decisions in the code as to what time periods and sites to be included in the trend calculations. These need to be checked and possibly updated each time the trend calculations need to be run.

:::

## Data retrieval

This method uses a stored procedure (`pAir_MonDailyAllParams`) to retrieve **daily averages** from the [ecan website](https://data.ecan.govt.nz/Catalogue/Method?MethodId=98#tab-data). The averages are calculated by a stored procedure `dbo.XXsomethingXX` and stored within the Envista database. The relevant table in the Envista database is `dbo.Alldaily.`

For this document we can just use the website to retrieve the data in `.csv` format. The inputs are a start date, end date and a station. The dates of interest here are for a 10 year period.

```{r}
#| label: date-setup

from_date <- "1/01/2015"
to_date <- "31/12/2024"

### Number of full years check
# Convert type and add a day to account for days between
to_date_mod <- dmy(to_date) + 1
from_date_mod <- dmy(from_date)
time_length(interval(start = from_date_mod, end = to_date_mod), "years")

# Without the + 1 then the time_length should be less than a whole year
time_length(interval(start = from_date_mod, end = to_date_mod - 1), "years")

```

Now we need to get a list of all stations available via the website which uses another procedure. Not all stations will have data available but this is taken care of later by ignoring the return if the httr request returns an http error.

```{r}
#| label: get-stations

# URL for getting list of available stations
response_stations <- httr::GET(
  'http://data.ecan.govt.nz/data/23/Air/Air%20quality%20sites%20monitored/CSV'
  )

# Basic list of stations as .csv file using URL above
station_id_list <- content(
  response_stations,
  encoding = "UTF-8",
  show_col_types = FALSE
  ) |>
  # Convert to data frame
  data.frame() |>  
  mutate(LatestDateTime = lubridate::dmy_hms(LatestDateTime))

```

Now can continue on with getting the data via the website.

```{r}
#| label: station-parameters

# This is the base URL we want to use before adding parameters
url_1 <- "https://data.ecan.govt.nz:443/data/98/Air/"
url_2 <- "Air%20quality%20data%20for%20a%20monitored%20site%20(daily)/CSV?"
base_url = paste0(url_1, url_2)

# Get the date into the right format for URL
from_date_url <- stringr::str_replace_all(from_date,"/","%2F")
to_date_url <- stringr::str_replace_all(to_date,"/","%2F")

```



Now can make the actual request in a loop to retrieve data for all stations which have available data via the ecan website.

```{r}
#| label: get-data-all-stations

# Initialise datalist to be populated inside the for loop
datalist = list()   

# For loop to make request of each station
for (ii in station_id_list$SiteNo) {
  
  # Make basic URL string
  URL_string <- paste0(
    base_url, "SiteID=", as.character(ii), "&",
    "StartDate=", as.character(from_date_url), "&",
    "EndDate=", as.character(to_date_url)
    )   
  
  # Encode URL string as URL
  URL_request <- utils::URLencode(URL_string)   

  # Send URL request message
  response <- httr::GET(URL_request)
  
  # Stop if response code is not OK. Could include other codes in future
  if (response$status_code != 200) {
    next
  }

  # Response for that station received
  dat_raw <- content(
    response,
    encoding = "UTF-8",
    show_col_types = FALSE,
    as = "text"
    )   
  
  # Parse text to data table
  dat <- read.table(
    text = dat_raw,
    sep = ",",
    header = TRUE,
    stringsAsFactors = FALSE
    ) 
  
  # Simplify column names
  names(dat) <- gsub(x = names(dat), pattern = "\\.", replacement = "")  
  
  # Different variables at each station
  dat_longer <- pivot_longer(
    dat,
    !c(DateTime, StationName)
    ) |> 
    mutate(
      value = janitor::round_half_up(value, 1)
    )

  # Change date format
  dat_longer$DateTime <- lubridate::ymd(dat_longer$DateTime)   

  # add it tolist
  datalist[[ii]] <- dat_longer   
}

# Combine data into one big table as a data frame
df_final_long = do.call(rbind, datalist)   

# This is handy for checking with database to more significant figures.
options(pillar.sigfig = 7)
```

## Data cleaning and decisions

Now need to get the data in a better state for Theil-Sen analysis. First some reformatting and renaming.

```{r}
#| label: data-cleaning

# Reformat data
df_daily_pm <- df_final_long |>
  # Select only PM10 and PM2.5
  filter(name %in% c("PM10ugm3", "PM25ugm3")) |>
  # Reformat to wide
  pivot_wider(
    names_from = name,
    values_from = value
    ) |>
  # "date" column required by openair
  rename(
    date = DateTime,
    PM10 = PM10ugm3,
    PM25 = PM25ugm3,
    site = StationName
    ) |>
  # Add columns for data checking
  mutate(
    month = lubridate::month(date),
    year = lubridate::year(date),
    days_per_month = lubridate::days_in_month(date)
    )


```

Before doing the trend estimate it is a good idea to plot the data to check for holes with the function `openair::summaryPlot()`.

```{r}
#| label: pm10-summary-plot-raw
#| column: page-right
#| fig-width: 20
#| fig-height: 30

p_sum_pm10_raw <- select(df_daily_pm, c("date", "site", "PM10")) |>
  # treat date as.character to make % data capture work for summaryPlot
  mutate(date = as.character(date)) |> 
  openair::summaryPlot(
    pollutant = "PM10",
    type = "site",
    fontsize = 20
  )

```

And PM~2.5~

```{r}
#| label: pm25-summary-plot-raw
#| column: page-right
#| fig-width: 20
#| fig-height: 30

p_sum_pm25_raw <- select(df_daily_pm, c("date", "site", "PM25")) |> 
  # treat date as.character to make % data capture work for summaryPlot
  mutate(date = as.character(date)) |> 
  openair::summaryPlot(
    pollutant = "PM25",
    type = "site",
    fontsize = 20
  )


```
The  summary plots show some decisions need to be made as to which sites to include and which periods should be used. The selection of periods are based on the [trend information sheet](https://boplass2.sharepoint.com/:w:/r/sites/NationalAirQualityGrp/_layouts/15/Doc.aspx?sourcedoc=%7BCD47641A-F0E7-420C-B974-40EF61C84B4D%7D&file=LAWA%20air%20quality%20trends%20guidance%2013022022.docx&_DSL=1&action=default&mobileredirect=true). The main decision point is that recent data should be discarded and trends calculated from the period prior if there are large holes (> 5 months) in the data.

The following is a list of the decisions made. The code should reflect these decisions as well.

- No trend should be calculated for Washdyke as the site has been changed and there has been a significant change in concentrations and occurrence of exceedances so we can remove those Washdyke stations from the data set.
- For St Albans, the site was shut down on 2020-11-11 so that will be the end date for this trend analysis for St Albans. There are still six consecutive years (just!) at the old Coles Place site which is enough for trend analysis.

```{r}
#| label: data-additional-decisions

# These need updating each year trends are calculated

df_daily_pm_clean <- df_daily_pm |>
  # Remove Washdyke Flat Road and Waimate Stadium site
  filter(!(site %in% c("Washdyke Flat Road", "Waimate Stadium"))) |> 
  
  # Remove St Albans data prior to this date due to site movement. There are still six consecutive years with over 75%
  filter(!(site == "St Albans EP"))

```

```{r}
#| label: pm10-summary-plot-clean
#| column: page-right
#| fig-width: 20
#| fig-height: 30

p_sum_pm10_clean <- select(df_daily_pm_clean, c("date", "site", "PM10")) |> 
  # treat date as.character to make % data capture work for summaryPlot
  mutate(date = as.character(date)) |> 
  openair::summaryPlot(
    pollutant = "PM10",
    type = "site",
    fontsize = 20
  )

```

And PM~2.5~

```{r}
#| label: pm25-summary-plot-clean
#| column: page-right
#| fig-width: 20
#| fig-height: 30

p_sum_pm25_clean <- select(df_daily_pm_clean, c("date", "site", "PM25")) |>
  # treat date as.character to make % data capture work for summaryPlot
  mutate(date = as.character(date)) |> 
  openair::summaryPlot(
    pollutant = "PM25",
    type = "site",
    fontsize = 20
  )


```




## Theil-Sen analysis

So now we can run the Theil-Sen trend analysis on the PM~10~ and PM~2.5~ datasets

```{r}
#| label: trend-analysis-pm10
#| fig-width: 20
#| fig-height: 20
#| column: page-right

# PM10 trend analysis

p_pm10 <- openair::TheilSen(
  df_daily_pm_clean,
  pollutant = "PM10",
  deseason = TRUE,
  date.format = "%Y",
  type = "site",
  data.thresh = 75,
  fontsize = 30
  )

```

```{r}
#| label: trend-analysis-pm25
#| fig-width: 20
#| fig-height: 20
#| column: page-right

# And TheilSen for PM2.5
p_pm25 <- openair::TheilSen(
  df_daily_pm_clean,
  pollutant = "PM25",
  deseason = TRUE,
  date.format = "%Y",
  type = "site",
  data.thresh = 75,
  fontsize = 30
  )


```

## Data export

Here the data is exported to show what has been used in the trend analysis calculations for comparison or to reproduce somewhere else without running the data grab from the website.

```{r}
#| label: data-export

df_final_wide <- pivot_wider(df_final_long, names_from = "name", values_from = "value")

write.csv(
  df_final_wide,
  file = paste0("data_export_",Sys.Date() ,".csv")
  )

# Note most of the data worked with is in the long format
head(df_final_long)
# as oppposed to the wide format which is exported here
head(df_final_wide)

```


## Trend analysis using `.csv` file

We can also run the same analysis using data retrieved from a .csv file. This is handy for comparison.

::: callout-note
Note the dataset dates need to match if comparing .csv read and retrievals from the website
:::

### Get the data

This assumes the data has been prepared in a .csv file which is included in this [GitHub](https://github.com/bws200/theil-sen-trend-analysis-ecan) repository under `/data`. It is for Environment Canterbury's Rangiora site only. A larger .csv file could be created which includes site name as an additional column.

```{r}
#| label: data-read-csv
#| column: page-right

# Read file
df_csv <- read.csv(
  file = "data/Rangiora PM10 2013 to 2022.csv"
) |>
  rename(
    date = DateTime,
    PM10 = PM10..ug.m3.,
    PM25 = PM2.5..ug.m3.
  ) |>
  mutate(date = lubridate::dmy(date)) |>
  filter(date >= "2016-01-01")

df_csv |> 
  # Add as.character to make data %'s work ok
  mutate(date = as.character(date)) |> 
  openair::summaryPlot(
    pollutant = "PM25"
  )

```

::: callout-note
The `.csv` dataset is not complete for 2022
:::

```{r}
#| label: trend-analysis-pm10-csv
#| column: page-right

# Run the trend analysis
openair::TheilSen(
  df_csv,
  pollutant = "PM25",
  deseason = TRUE,
  date.format = "%Y",
  data.thresh = 75
)

```

## Rounding {.appendix}

The standard round function in R doesn't work like others in excel so another function needs to be added. See this [Stack Overflow discussion](https://stackoverflow.com/questions/12688717/round-up-from-5) for more discussion on rounding in R.

```{r}
#| label: data-note-on-rounding

# Round 0.5 is expected to round to 1 but R rounds it down to 0
round(0.5)

# But instead we need a function to round like excel e.g. Function to always round 0.5 up
round2 <- function(x, digits = 0) {
  posneg <- sign(x)
  z <- abs(x) * 10^digits
  z <- z + 0.5
  z <- trunc(z)
  z <- z / 10^digits
  z * posneg
}

# And try again with round2 which should round to 1
round2(0.5)

# An easier method is just using the in-built janitor::round_half_up function which implements the same round2 function but without defining it
janitor::round_half_up(0.5)

```

